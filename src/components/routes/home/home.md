## Research


### Machine Learning
My current research focus is in Reinforcement Learning and Representation Learning. I am specifically interested in the integration of these two fields. Modern machine learning research has been dominated by deep learning, but the mentality of increasing the number of parameters to improve performance is not going to continue being computationally tractable. It is important to find more meaningful representations to allow use of lower free-parameter models to preserve computational tractability.

#### Supervised Autoencoders and Supervised Dictionary Learning for representation learning.
Can the incorporation of the reconstructive loss improve the generalization of supervised learning algorithms, and can the inclusion of the predictive loss improve the discriminability of the reconstruction of unsupervised algorithms?

#### General Value Functions for predictive knowledge
By learning generalized value functions from the Reinforcement Learning domain, can we create useful predictive representations? We specify interesting questions by altering the gamma returns, the policy, and the rewards for each GVF. We show that by using Temporal-Difference learning methods, we can make one-step predictions answering the specified questions. These questions could be myopic questions (questions specifying the immediate next observation following some policy), horizon questions (observation in some number of steps following some policy), or termination questions (observation after some event following a policy).


### Neuroscience
My current work involves the analysis of diffusion data. I am assisting in the development of an open-source data warehouse for diffusion data derivatives (o3d). I develop data analysis pipelines for rotating neuro-images, fasicle extraction, and tract classification.